# tests/test_embedding_model.py
"""
æµ‹è¯• BGE-M3 åµŒå…¥æ¨¡å‹
"""

import sys
sys.path.append('.')

import numpy as np
import time
from models.embedding_model import get_embedding_model, encode_text, batch_encode_texts

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("\n1. æµ‹è¯•æ¨¡å‹åŠ è½½...")
    
    try:
        start_time = time.time()
        model = get_embedding_model()
        load_time = time.time() - start_time
        
        print(f"   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   åŠ è½½æ—¶é—´: {load_time:.2f} ç§’")
        print(f"   æ¨¡å‹åç§°: {model.model_name}")
        print(f"   è¿è¡Œè®¾å¤‡: {model.device_type}")
        print(f"   å‘é‡ç»´åº¦: {model.get_dimension()}")
        
        return True
    except Exception as e:
        print(f"   âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def test_single_text_encoding():
    """æµ‹è¯•å•ä¸ªæ–‡æœ¬ç¼–ç """
    print("\n2. æµ‹è¯•å•ä¸ªæ–‡æœ¬ç¼–ç ...")
    
    try:
        # æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "å¹³å®‰é“¶è¡Œå‘å¸ƒ2024å¹´ç¬¬ä¸€å­£åº¦è´¢æŠ¥",
            "äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›",
            "è‚¡ç¥¨å¸‚åœºä»Šæ—¥æ•´ä½“è¡¨ç°è‰¯å¥½ï¼Œæ²ªæ·±300æŒ‡æ•°ä¸Šæ¶¨2.5%",
            "The stock market performed well today",  # æµ‹è¯•è‹±æ–‡
            ""  # æµ‹è¯•ç©ºæ–‡æœ¬
        ]
        
        model = get_embedding_model()
        
        for text in test_texts:
            if text:
                print(f"\n   æµ‹è¯•æ–‡æœ¬: '{text[:30]}...'")
            else:
                print(f"\n   æµ‹è¯•æ–‡æœ¬: '[ç©ºæ–‡æœ¬]'")
                
            start_time = time.time()
            embedding = encode_text(text)
            encode_time = time.time() - start_time
            
            print(f"   å‘é‡å½¢çŠ¶: {embedding.shape}")
            print(f"   å‘é‡èŒƒæ•°: {np.linalg.norm(embedding):.4f}")
            print(f"   ç¼–ç æ—¶é—´: {encode_time*1000:.2f} ms")
            
            # æ£€æŸ¥å‘é‡æ˜¯å¦å½’ä¸€åŒ–
            if not text:
                print(f"   ç©ºæ–‡æœ¬å¤„ç†: {'âœ… è¿”å›é›¶å‘é‡' if np.allclose(embedding, 0) else 'âŒ éé›¶å‘é‡'}")
            else:
                is_normalized = np.abs(np.linalg.norm(embedding) - 1.0) < 0.01
                print(f"   å½’ä¸€åŒ–: {'âœ…' if is_normalized else 'âŒ'}")
        
        return True
    except Exception as e:
        print(f"   âŒ å•æ–‡æœ¬ç¼–ç å¤±è´¥: {e}")
        return False

def test_batch_encoding():
    """æµ‹è¯•æ‰¹é‡ç¼–ç """
    print("\n3. æµ‹è¯•æ‰¹é‡ç¼–ç ...")
    
    try:
        # å‡†å¤‡æ‰¹é‡æ–‡æœ¬
        texts = [
            "æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨",
            "è‚¡ç¥¨æŠ•èµ„éœ€è¦å…³æ³¨å…¬å¸åŸºæœ¬é¢",
            "é‡åŒ–äº¤æ˜“ç­–ç•¥çš„ä¼˜åŒ–æ–¹æ³•",
            "ESGæŠ•èµ„ç†å¿µé€æ¸æˆä¸ºä¸»æµ",
            "åŒºå—é“¾æŠ€æœ¯åœ¨é‡‘èç§‘æŠ€ä¸­çš„åˆ›æ–°åº”ç”¨",
            "",  # ç©ºæ–‡æœ¬
            "äººå·¥æ™ºèƒ½åŠ©åŠ›æ™ºæ…§é‡‘èå‘å±•"
        ] * 10  # é‡å¤10æ¬¡ï¼Œå…±70ä¸ªæ–‡æœ¬
        
        print(f"   æ‰¹é‡å¤§å°: {len(texts)} ä¸ªæ–‡æœ¬")
        
        # æµ‹è¯•æ‰¹é‡ç¼–ç 
        start_time = time.time()
        embeddings = batch_encode_texts(texts, batch_size=32, show_progress_bar=False)
        batch_time = time.time() - start_time
        
        print(f"   âœ… æ‰¹é‡ç¼–ç æˆåŠŸ")
        print(f"   è¿”å›å‘é‡æ•°: {len(embeddings)}")
        print(f"   æ€»æ—¶é—´: {batch_time:.2f} ç§’")
        print(f"   å¹³å‡æ—¶é—´: {batch_time/len(texts)*1000:.2f} ms/æ–‡æœ¬")
        
        # æ£€æŸ¥ç»“æœ
        valid_embeddings = [emb for emb in embeddings if not np.allclose(emb, 0)]
        print(f"   æœ‰æ•ˆå‘é‡æ•°: {len(valid_embeddings)}")
        
        return True
    except Exception as e:
        print(f"   âŒ æ‰¹é‡ç¼–ç å¤±è´¥: {e}")
        return False

def test_similarity():
    """æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—"""
    print("\n4. æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—...")
    
    try:
        model = get_embedding_model()
        
        # æµ‹è¯•ç›¸ä¼¼æ–‡æœ¬
        text_pairs = [
            ("è‚¡ç¥¨å¸‚åœºåˆ†æ", "è‚¡ç¥¨å¸‚åœºç ”ç©¶"),  # é«˜ç›¸ä¼¼åº¦
            ("äººå·¥æ™ºèƒ½æŠ€æœ¯", "AIæŠ€æœ¯åº”ç”¨"),      # ä¸­ç­‰ç›¸ä¼¼åº¦
            ("è‚¡ç¥¨æŠ•èµ„ç­–ç•¥", "å¤©æ°”é¢„æŠ¥ä¿¡æ¯"),    # ä½ç›¸ä¼¼åº¦
            ("å¹³å®‰é“¶è¡Œ", "å¹³å®‰é“¶è¡Œ")            # ç›¸åŒæ–‡æœ¬
        ]
        
        for text1, text2 in text_pairs:
            similarity = model.compute_similarity(text1, text2)
            print(f"\n   æ–‡æœ¬1: '{text1}'")
            print(f"   æ–‡æœ¬2: '{text2}'")
            print(f"   ç›¸ä¼¼åº¦: {similarity:.4f}")
        
        # æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦
        vec1 = encode_text("é‡‘èç§‘æŠ€åˆ›æ–°")
        vec2 = encode_text("é‡‘èæŠ€æœ¯é©æ–°")
        vec_similarity = model.compute_similarity(vec1, vec2)
        print(f"\n   å‘é‡ç›¸ä¼¼åº¦æµ‹è¯•: {vec_similarity:.4f}")
        
        return True
    except Exception as e:
        print(f"   âŒ ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
        return False

def test_real_data():
    """æµ‹è¯•çœŸå®æ•°æ®ç¼–ç """
    print("\n5. æµ‹è¯•çœŸå®è‚¡ç¥¨æ•°æ®ç¼–ç ...")
    
    try:
        # æ¨¡æ‹ŸçœŸå®çš„è‚¡ç¥¨ç›¸å…³æ–‡æœ¬
        real_texts = [
            "å¹³å®‰é“¶è¡Œï¼ˆ000001.SZï¼‰2024å¹´ç¬¬ä¸€å­£åº¦å®ç°è¥ä¸šæ”¶å…¥442.89äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿2.8%ï¼›å½’å±äºæœ¬è¡Œè‚¡ä¸œçš„å‡€åˆ©æ¶¦142.52äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿10.1%ã€‚",
            "æŠ•èµ„è€…é—®ï¼šå…¬å¸åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸæœ‰å“ªäº›å¸ƒå±€ï¼Ÿå›ç­”ï¼šå…¬å¸é«˜åº¦é‡è§†äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨ï¼Œå·²åœ¨æ™ºèƒ½å®¢æœã€é£é™©æ§åˆ¶ç­‰å¤šä¸ªé¢†åŸŸå–å¾—ç§¯æè¿›å±•ã€‚",
            "ã€èµ„é‡‘æµå‘ã€‘å¹³å®‰é“¶è¡Œä»Šæ—¥ä¸»åŠ›èµ„é‡‘å‡€æµå…¥2.3äº¿å…ƒï¼Œå…¶ä¸­è¶…å¤§å•å‡€æµå…¥1.5äº¿å…ƒï¼Œæ˜¾ç¤ºæœºæ„èµ„é‡‘çœ‹å¥½ã€‚",
            "ã€å…¬å‘Šã€‘å¹³å®‰é“¶è¡Œå…³äº2024å¹´å¹´åº¦æƒç›Šåˆ†æ´¾å®æ–½å…¬å‘Šï¼šæ¯10è‚¡æ´¾å‘ç°é‡‘çº¢åˆ©3.18å…ƒï¼ˆå«ç¨ï¼‰ã€‚"
        ]
        
        embeddings = batch_encode_texts(real_texts)
        
        print(f"   âœ… æˆåŠŸç¼–ç  {len(embeddings)} ä¸ªçœŸå®æ–‡æœ¬")
        
        # è®¡ç®—æ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦çŸ©é˜µ
        print("\n   ç›¸ä¼¼åº¦çŸ©é˜µ:")
        print("   ", end="")
        for i in range(len(real_texts)):
            print(f"æ–‡æœ¬{i+1:2d}", end=" ")
        print()
        
        for i in range(len(real_texts)):
            print(f"   æ–‡æœ¬{i+1}", end=" ")
            for j in range(len(real_texts)):
                if i == j:
                    sim = 1.0
                else:
                    sim = np.dot(embeddings[i], embeddings[j])
                print(f"{sim:5.3f}", end=" ")
            print()
        
        return True
    except Exception as e:
        print(f"   âŒ çœŸå®æ•°æ®ç¼–ç å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ BGE-M3 åµŒå…¥æ¨¡å‹æµ‹è¯•")
    print("=" * 70)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("æ¨¡å‹åŠ è½½", test_model_loading),
        ("å•æ–‡æœ¬ç¼–ç ", test_single_text_encoding),
        ("æ‰¹é‡ç¼–ç ", test_batch_encoding),
        ("ç›¸ä¼¼åº¦è®¡ç®—", test_similarity),
        ("çœŸå®æ•°æ®", test_real_data)
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\n{'='*70}")
        print(f"æµ‹è¯•: {test_name}")
        print('='*70)
        
        success = test_func()
        results.append((test_name, success))
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
    
    all_passed = all(success for _, success in results)
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åµŒå…¥æ¨¡å‹å·²å‡†å¤‡å°±ç»ªã€‚")
        print("\nä¸‹ä¸€æ­¥ï¼šå®ç°æ–‡æ¡£å¤„ç†æ¨¡å— (rag/document_processor.py)")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")

if __name__ == "__main__":
    main()