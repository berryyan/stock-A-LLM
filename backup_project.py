#!/usr/bin/env python3
"""
è‚¡ç¥¨åˆ†æç³»ç»Ÿ - æ™ºèƒ½å¤‡ä»½å·¥å…·
æ”¯æŒå¢é‡å¤‡ä»½ã€å‹ç¼©å¤‡ä»½ã€é€‰æ‹©æ€§å¤‡ä»½ç­‰åŠŸèƒ½
"""

import os
import shutil
import zipfile
from datetime import datetime
from pathlib import Path
import argparse
import json
import time

class ProjectBackup:
    def __init__(self):
        self.project_root = Path.cwd()
        self.backup_base_dir = self.project_root.parent
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # é»˜è®¤æ’é™¤çš„æ–‡ä»¶å’Œç›®å½•
        self.default_ignore_patterns = [
            # Pythonç›¸å…³
            '__pycache__',
            '*.pyc',
            '*.pyo',
            '*.pyd',
            '.Python',
            'pip-log.txt',
            'pip-delete-this-directory.txt',
            '.tox/',
            '.coverage',
            '.coverage.*',
            '.cache',
            '.pytest_cache/',
            'htmlcov/',
            '*.egg-info/',
            '*.egg',
            
            # è™šæ‹Ÿç¯å¢ƒ
            'stock_analysis_env/',
            'venv/',
            'env/',
            'ENV/',
            
            # IDE
            '.idea/',
            '.vscode/',
            '*.swp',
            '*.swo',
            '*~',
            
            # Git
            '.git/',
            '.gitignore',
            
            # æ—¥å¿—
            '*.log',
            'logs/',
            
            # å¤§æ–‡ä»¶å’Œç¼“å­˜
            'data/pdfs/cache/',
            'data/milvus/',
            'models/bge-m3/.git/',
            'models/bge-m3/onnx/',
            '*.bin',
            '*.pth',
            '*.h5',
            '*.safetensors',
            
            # ä¸´æ—¶æ–‡ä»¶
            '.DS_Store',
            'Thumbs.db',
            'desktop.ini',
            
            # å¤‡ä»½æ–‡ä»¶
            '*.backup',
            '*.bak',
            'backup_*',
            'archive/',
        ]
        
        # é‡è¦æ–‡ä»¶åˆ—è¡¨ï¼ˆå³ä½¿åœ¨å¿½ç•¥ç›®å½•ä¸­ä¹Ÿè¦å¤‡ä»½ï¼‰
        self.important_files = [
            '.env.example',
            'requirements.txt',
            'README.md',
            'setup.py',
        ]

    def calculate_size(self, path):
        """è®¡ç®—ç›®å½•å¤§å°"""
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                if os.path.exists(filepath):
                    total_size += os.path.getsize(filepath)
        return total_size

    def format_size(self, size):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024.0:
                return f"{size:.2f} {unit}"
            size /= 1024.0
        return f"{size:.2f} TB"

    def create_backup_info(self, backup_path, start_time, file_count):
        """åˆ›å»ºå¤‡ä»½ä¿¡æ¯æ–‡ä»¶"""
        end_time = time.time()
        info = {
            "backup_date": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "source_path": str(self.project_root),
            "backup_path": str(backup_path),
            "file_count": file_count,
            "backup_size": self.format_size(self.calculate_size(backup_path)),
            "duration_seconds": round(end_time - start_time, 2),
            "python_version": os.sys.version,
            "ignore_patterns": self.default_ignore_patterns
        }
        
        info_file = backup_path / "backup_info.json"
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        
        return info

    def should_ignore(self, path, ignore_patterns):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥æŸä¸ªè·¯å¾„"""
        path_str = str(path)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é‡è¦æ–‡ä»¶
        for important in self.important_files:
            if path_str.endswith(important):
                return False
        
        # æ£€æŸ¥å¿½ç•¥æ¨¡å¼
        for pattern in ignore_patterns:
            if pattern.endswith('/'):
                # ç›®å½•æ¨¡å¼
                if f"/{pattern}" in path_str or path_str.endswith(pattern[:-1]):
                    return True
            elif '*' in pattern:
                # é€šé…ç¬¦æ¨¡å¼
                import fnmatch
                if fnmatch.fnmatch(path_str, pattern):
                    return True
            else:
                # ç²¾ç¡®åŒ¹é…
                if pattern in path_str:
                    return True
        
        return False

    def copy_with_progress(self, src, dst, ignore_patterns=None):
        """å¸¦è¿›åº¦æ˜¾ç¤ºçš„å¤åˆ¶"""
        if ignore_patterns is None:
            ignore_patterns = self.default_ignore_patterns
        
        total_files = 0
        copied_files = 0
        skipped_files = 0
        
        # å…ˆè®¡ç®—æ€»æ–‡ä»¶æ•°
        print("ğŸ“Š æ­£åœ¨ç»Ÿè®¡æ–‡ä»¶...")
        for root, dirs, files in os.walk(src):
            dirs[:] = [d for d in dirs if not self.should_ignore(Path(root) / d, ignore_patterns)]
            for file in files:
                if not self.should_ignore(Path(root) / file, ignore_patterns):
                    total_files += 1
        
        print(f"ğŸ“ å‘ç° {total_files} ä¸ªéœ€è¦å¤‡ä»½çš„æ–‡ä»¶\n")
        
        # å¼€å§‹å¤åˆ¶
        for root, dirs, files in os.walk(src):
            # è¿‡æ»¤ç›®å½•
            dirs[:] = [d for d in dirs if not self.should_ignore(Path(root) / d, ignore_patterns)]
            
            # åˆ›å»ºç›®æ ‡ç›®å½•
            rel_path = Path(root).relative_to(src)
            dst_dir = dst / rel_path
            if not dst_dir.exists():
                dst_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æ–‡ä»¶
            for file in files:
                src_file = Path(root) / file
                dst_file = dst_dir / file
                
                if self.should_ignore(src_file, ignore_patterns):
                    skipped_files += 1
                    continue
                
                try:
                    shutil.copy2(src_file, dst_file)
                    copied_files += 1
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    if copied_files % 100 == 0 or copied_files == total_files:
                        progress = (copied_files / total_files) * 100
                        bar_length = 30
                        filled_length = int(bar_length * copied_files // total_files)
                        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
                        print(f'\rè¿›åº¦: [{bar}] {progress:.1f}% ({copied_files}/{total_files})', end='')
                        
                except Exception as e:
                    print(f"\nâš ï¸  å¤åˆ¶å¤±è´¥: {src_file} - {e}")
        
        print(f"\n\nâœ… å¤åˆ¶å®Œæˆ: {copied_files} ä¸ªæ–‡ä»¶")
        if skipped_files > 0:
            print(f"â­ï¸  è·³è¿‡æ–‡ä»¶: {skipped_files} ä¸ª")
        
        return copied_files

    def create_full_backup(self, compress=False, custom_name=None):
        """åˆ›å»ºå®Œæ•´å¤‡ä»½"""
        backup_name = custom_name or f"stock_analysis_backup_{self.timestamp}"
        backup_path = self.backup_base_dir / backup_name
        
        print(f"ğŸš€ å¼€å§‹å¤‡ä»½é¡¹ç›®...")
        print(f"ğŸ“ æºç›®å½•: {self.project_root}")
        print(f"ğŸ“ ç›®æ ‡ç›®å½•: {backup_path}")
        print(f"ğŸ“… æ—¶é—´æˆ³: {self.timestamp}\n")
        
        start_time = time.time()
        
        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            backup_path.mkdir(parents=True, exist_ok=True)
            
            # å¤åˆ¶æ–‡ä»¶
            file_count = self.copy_with_progress(self.project_root, backup_path)
            
            # åˆ›å»ºå¤‡ä»½ä¿¡æ¯
            info = self.create_backup_info(backup_path, start_time, file_count)
            
            # å¦‚æœéœ€è¦å‹ç¼©
            if compress:
                print("\nğŸ“¦ æ­£åœ¨å‹ç¼©å¤‡ä»½...")
                zip_path = backup_path.with_suffix('.zip')
                
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for root, dirs, files in os.walk(backup_path):
                        for file in files:
                            file_path = Path(root) / file
                            arcname = file_path.relative_to(backup_path)
                            zipf.write(file_path, arcname)
                
                # åˆ é™¤æœªå‹ç¼©çš„å¤‡ä»½
                shutil.rmtree(backup_path)
                
                zip_size = self.format_size(os.path.getsize(zip_path))
                print(f"âœ… å‹ç¼©å®Œæˆï¼å‹ç¼©åŒ…å¤§å°: {zip_size}")
                print(f"ğŸ“ å‹ç¼©åŒ…ä½ç½®: {zip_path}")
            else:
                print(f"\nğŸ“Š å¤‡ä»½ç»Ÿè®¡:")
                print(f"  - å¤‡ä»½æ–‡ä»¶æ•°: {info['file_count']}")
                print(f"  - å¤‡ä»½å¤§å°: {info['backup_size']}")
                print(f"  - è€—æ—¶: {info['duration_seconds']} ç§’")
                print(f"\nâœ… å¤‡ä»½å®Œæˆï¼")
                print(f"ğŸ“ å¤‡ä»½ä½ç½®: {backup_path.absolute()}")
                
        except Exception as e:
            print(f"\nâŒ å¤‡ä»½å¤±è´¥: {e}")
            if backup_path.exists():
                print("ğŸ§¹ æ¸…ç†æœªå®Œæˆçš„å¤‡ä»½...")
                shutil.rmtree(backup_path)
            raise

    def create_code_only_backup(self):
        """åªå¤‡ä»½ä»£ç æ–‡ä»¶ï¼ˆä¸åŒ…æ‹¬æ•°æ®å’Œæ¨¡å‹ï¼‰"""
        # æ·»åŠ é¢å¤–çš„å¿½ç•¥æ¨¡å¼
        code_ignore_patterns = self.default_ignore_patterns + [
            'data/',
            'models/',
            '*.pdf',
            '*.csv',
            '*.xlsx',
            '*.json',
            '*.pkl',
            '*.npy',
            '*.npz',
        ]
        
        backup_name = f"stock_analysis_code_only_{self.timestamp}"
        backup_path = self.backup_base_dir / backup_name
        
        print(f"ğŸš€ å¼€å§‹å¤‡ä»½ä»£ç æ–‡ä»¶...")
        print(f"ğŸ“ æºç›®å½•: {self.project_root}")
        print(f"ğŸ“ ç›®æ ‡ç›®å½•: {backup_path}")
        print("ğŸ“ ç±»å‹: ä»…ä»£ç æ–‡ä»¶\n")
        
        start_time = time.time()
        
        try:
            backup_path.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨è‡ªå®šä¹‰å¿½ç•¥æ¨¡å¼å¤åˆ¶
            old_patterns = self.default_ignore_patterns
            self.default_ignore_patterns = code_ignore_patterns
            
            file_count = self.copy_with_progress(self.project_root, backup_path)
            
            self.default_ignore_patterns = old_patterns
            
            info = self.create_backup_info(backup_path, start_time, file_count)
            
            print(f"\nâœ… ä»£ç å¤‡ä»½å®Œæˆï¼")
            print(f"ğŸ“ å¤‡ä»½ä½ç½®: {backup_path.absolute()}")
            
        except Exception as e:
            print(f"\nâŒ å¤‡ä»½å¤±è´¥: {e}")
            if backup_path.exists():
                shutil.rmtree(backup_path)
            raise

    def list_backups(self):
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½"""
        print("ğŸ“‹ ç°æœ‰å¤‡ä»½åˆ—è¡¨:\n")
        
        backups = []
        for item in self.backup_base_dir.iterdir():
            if item.is_dir() and 'stock_analysis_backup' in item.name:
                info_file = item / 'backup_info.json'
                if info_file.exists():
                    with open(info_file, 'r', encoding='utf-8') as f:
                        info = json.load(f)
                        backups.append((item.name, info))
                else:
                    # æ—§å¤‡ä»½å¯èƒ½æ²¡æœ‰infoæ–‡ä»¶
                    size = self.format_size(self.calculate_size(item))
                    backups.append((item.name, {"backup_size": size}))
        
        if not backups:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½")
            return
        
        for name, info in sorted(backups, reverse=True):
            print(f"ğŸ“ {name}")
            if 'backup_date' in info:
                print(f"   æ—¥æœŸ: {info['backup_date']}")
            if 'file_count' in info:
                print(f"   æ–‡ä»¶: {info['file_count']} ä¸ª")
            print(f"   å¤§å°: {info.get('backup_size', 'æœªçŸ¥')}")
            print()

def main():
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨åˆ†æç³»ç»Ÿå¤‡ä»½å·¥å…·')
    parser.add_argument('--compress', '-c', action='store_true', 
                       help='åˆ›å»ºå‹ç¼©å¤‡ä»½ï¼ˆZIPæ ¼å¼ï¼‰')
    parser.add_argument('--code-only', action='store_true',
                       help='åªå¤‡ä»½ä»£ç æ–‡ä»¶ï¼ˆä¸åŒ…æ‹¬æ•°æ®å’Œæ¨¡å‹ï¼‰')
    parser.add_argument('--name', type=str,
                       help='è‡ªå®šä¹‰å¤‡ä»½åç§°')
    parser.add_argument('--list', '-l', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¤‡ä»½')
    
    args = parser.parse_args()
    
    backup = ProjectBackup()
    
    try:
        if args.list:
            backup.list_backups()
        elif args.code_only:
            backup.create_code_only_backup()
        else:
            backup.create_full_backup(compress=args.compress, custom_name=args.name)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  å¤‡ä»½è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
